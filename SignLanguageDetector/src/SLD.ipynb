{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ZMiZW9zn2X",
        "outputId": "e7d80a41-1f27-4b7c-ccc4-bea6ab521cef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.34)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.34)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Downgrade TensorFlow to 2.15.0 and install compatible TF.js\n",
        "!pip install --upgrade --quiet tensorflow==2.15.0 tensorflowjs"
      ],
      "metadata": {
        "id": "cuBzz_gp3nxg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4quvuMNG4r49",
        "outputId": "b47340d2-5219-4ff9-d463-f5a0a33d2e83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 2.15.0\n",
            "Summary: Deep learning for humans.\n",
            "Home-page: https://keras.io/\n",
            "Author: Keras team\n",
            "Author-email: keras-users@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x4Qy2QG7tJ3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba975522-6e46-495e-ff16-f5881db310e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/30\n",
            "1942/1942 - 7s - loss: 0.9449 - accuracy: 0.6996 - 7s/epoch - 4ms/step\n",
            "Epoch 2/30\n",
            "1942/1942 - 5s - loss: 0.3229 - accuracy: 0.8954 - 5s/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "1942/1942 - 7s - loss: 0.2486 - accuracy: 0.9203 - 7s/epoch - 4ms/step\n",
            "Epoch 4/30\n",
            "1942/1942 - 5s - loss: 0.2178 - accuracy: 0.9280 - 5s/epoch - 3ms/step\n",
            "Epoch 5/30\n",
            "1942/1942 - 5s - loss: 0.1994 - accuracy: 0.9372 - 5s/epoch - 3ms/step\n",
            "Epoch 6/30\n",
            "1942/1942 - 6s - loss: 0.1865 - accuracy: 0.9388 - 6s/epoch - 3ms/step\n",
            "Epoch 7/30\n",
            "1942/1942 - 5s - loss: 0.1767 - accuracy: 0.9434 - 5s/epoch - 3ms/step\n",
            "Epoch 8/30\n",
            "1942/1942 - 7s - loss: 0.1716 - accuracy: 0.9453 - 7s/epoch - 4ms/step\n",
            "Epoch 9/30\n",
            "1942/1942 - 5s - loss: 0.1628 - accuracy: 0.9463 - 5s/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "1942/1942 - 5s - loss: 0.1575 - accuracy: 0.9497 - 5s/epoch - 3ms/step\n",
            "Epoch 11/30\n",
            "1942/1942 - 6s - loss: 0.1538 - accuracy: 0.9505 - 6s/epoch - 3ms/step\n",
            "Epoch 12/30\n",
            "1942/1942 - 5s - loss: 0.1492 - accuracy: 0.9517 - 5s/epoch - 3ms/step\n",
            "Epoch 13/30\n",
            "1942/1942 - 6s - loss: 0.1457 - accuracy: 0.9535 - 6s/epoch - 3ms/step\n",
            "Epoch 14/30\n",
            "1942/1942 - 6s - loss: 0.1416 - accuracy: 0.9542 - 6s/epoch - 3ms/step\n",
            "Epoch 15/30\n",
            "1942/1942 - 5s - loss: 0.1381 - accuracy: 0.9547 - 5s/epoch - 3ms/step\n",
            "Epoch 16/30\n",
            "1942/1942 - 7s - loss: 0.1360 - accuracy: 0.9561 - 7s/epoch - 3ms/step\n",
            "Epoch 17/30\n",
            "1942/1942 - 5s - loss: 0.1342 - accuracy: 0.9571 - 5s/epoch - 3ms/step\n",
            "Epoch 18/30\n",
            "1942/1942 - 6s - loss: 0.1282 - accuracy: 0.9584 - 6s/epoch - 3ms/step\n",
            "Epoch 19/30\n",
            "1942/1942 - 6s - loss: 0.1250 - accuracy: 0.9598 - 6s/epoch - 3ms/step\n",
            "Epoch 20/30\n",
            "1942/1942 - 5s - loss: 0.1239 - accuracy: 0.9598 - 5s/epoch - 3ms/step\n",
            "Epoch 21/30\n",
            "1942/1942 - 7s - loss: 0.1274 - accuracy: 0.9591 - 7s/epoch - 3ms/step\n",
            "Epoch 22/30\n",
            "1942/1942 - 5s - loss: 0.1134 - accuracy: 0.9629 - 5s/epoch - 3ms/step\n",
            "Epoch 23/30\n",
            "1942/1942 - 5s - loss: 0.1170 - accuracy: 0.9624 - 5s/epoch - 3ms/step\n",
            "Epoch 24/30\n",
            "1942/1942 - 6s - loss: 0.1152 - accuracy: 0.9625 - 6s/epoch - 3ms/step\n",
            "Epoch 25/30\n",
            "1942/1942 - 5s - loss: 0.1153 - accuracy: 0.9628 - 5s/epoch - 3ms/step\n",
            "Epoch 26/30\n",
            "1942/1942 - 7s - loss: 0.1111 - accuracy: 0.9647 - 7s/epoch - 3ms/step\n",
            "Epoch 27/30\n",
            "1942/1942 - 5s - loss: 0.1048 - accuracy: 0.9674 - 5s/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "1942/1942 - 5s - loss: 0.1100 - accuracy: 0.9645 - 5s/epoch - 3ms/step\n",
            "Epoch 29/30\n",
            "1942/1942 - 6s - loss: 0.1065 - accuracy: 0.9664 - 6s/epoch - 3ms/step\n",
            "Epoch 30/30\n",
            "1942/1942 - 5s - loss: 0.1074 - accuracy: 0.9654 - 5s/epoch - 3ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "\n",
            "=== Test Results ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00         1\n",
            "           B       1.00      1.00      1.00         1\n",
            "           C       1.00      1.00      1.00         1\n",
            "           D       1.00      1.00      1.00         1\n",
            "           E       1.00      1.00      1.00         1\n",
            "           G       1.00      1.00      1.00         1\n",
            "           H       1.00      1.00      1.00         1\n",
            "           I       1.00      1.00      1.00         1\n",
            "           J       1.00      1.00      1.00         1\n",
            "           K       1.00      1.00      1.00         1\n",
            "           L       1.00      1.00      1.00         1\n",
            "           M       1.00      1.00      1.00         1\n",
            "           Q       1.00      1.00      1.00         1\n",
            "           R       0.50      1.00      0.67         1\n",
            "           S       1.00      1.00      1.00         1\n",
            "           T       1.00      1.00      1.00         1\n",
            "           U       0.00      0.00      0.00         1\n",
            "           V       1.00      1.00      1.00         1\n",
            "           W       1.00      1.00      1.00         1\n",
            "           X       0.50      1.00      0.67         1\n",
            "           Y       1.00      1.00      1.00         1\n",
            "           Z       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.91        22\n",
            "   macro avg       0.86      0.91      0.88        22\n",
            "weighted avg       0.86      0.91      0.88        22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model converted and saved to /content/drive/MyDrive/SignLanguageDataset/models/tfjs_model\n",
            "  adding: content/drive/MyDrive/SignLanguageDataset/models/tfjs_model/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/SignLanguageDataset/models/tfjs_model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: content/drive/MyDrive/SignLanguageDataset/models/tfjs_model/model.json (deflated 79%)\n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL: Downgrade tensorflow-decision-forests only if needed\n",
        "# !pip install tensorflow-decision-forests==1.8.1\n",
        "\n",
        "# STEP 2: Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "from tensorflow.keras import layers, models, utils\n",
        "from mediapipe import solutions\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive\n",
        "\n",
        "# STEP 3: Mount Drive (if needed)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset paths\n",
        "data_train_dir = '/content/drive/MyDrive/SignLanguageDataset/data/train'\n",
        "data_test_dir = '/content/drive/MyDrive/SignLanguageDataset/data/test'\n",
        "\n",
        "# Processor class\n",
        "def get_processor():\n",
        "    class ASLProcessor:\n",
        "        def __init__(self):\n",
        "            self.mp_hands = solutions.hands.Hands(\n",
        "                static_image_mode=True,\n",
        "                max_num_hands=1,\n",
        "                min_detection_confidence=0.7\n",
        "            )\n",
        "            self.class_map = {\n",
        "                'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4,\n",
        "                'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9,\n",
        "                'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14,\n",
        "                'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19,\n",
        "                'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24,\n",
        "                'Z': 25, 'space': 26, 'del': 27, 'nothing': 28\n",
        "            }\n",
        "            self.reverse_map = {v: k for k, v in self.class_map.items()}\n",
        "\n",
        "        def load_train_data(self, data_dir):\n",
        "            X, y = [], []\n",
        "            for class_name in os.listdir(data_dir):\n",
        "                class_dir = os.path.join(data_dir, class_name)\n",
        "                if os.path.isdir(class_dir):\n",
        "                    for file in os.listdir(class_dir):\n",
        "                        if file.endswith('.npy'):\n",
        "                            data = np.load(os.path.join(class_dir, file))\n",
        "                            if data.shape == (63,):\n",
        "                                X.append(data)\n",
        "                                y.append(self.class_map[class_name])\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "        def process_test_image(self, image_path):\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                return None\n",
        "            results = self.mp_hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            if results.multi_hand_landmarks:\n",
        "                return np.array([\n",
        "                    [lm.x, lm.y, lm.z]\n",
        "                    for hand in results.multi_hand_landmarks\n",
        "                    for lm in hand.landmark\n",
        "                ]).flatten()\n",
        "            return None\n",
        "\n",
        "        def evaluate_model(self, model, test_dir):\n",
        "            X_test, y_true = [], []\n",
        "            for file in os.listdir(test_dir):\n",
        "                if file.lower().endswith(('.jpg', '.jpeg')):\n",
        "                    true_label = os.path.splitext(file)[0].lower()\n",
        "                    if true_label == 'del':\n",
        "                        true_label = 'del'\n",
        "                    elif true_label == 'space':\n",
        "                        true_label = 'space'\n",
        "                    elif true_label == 'nothing':\n",
        "                        true_label = 'nothing'\n",
        "                    else:\n",
        "                        true_label = true_label.upper()\n",
        "\n",
        "                    landmarks = self.process_test_image(os.path.join(test_dir, file))\n",
        "                    if landmarks is not None and landmarks.shape == (63,):\n",
        "                        X_test.append(landmarks)\n",
        "                        y_true.append(self.class_map.get(true_label, -1))\n",
        "\n",
        "            if not X_test:\n",
        "                raise ValueError(\"No valid test images found!\")\n",
        "\n",
        "            X_test = np.array(X_test)\n",
        "            y_true = np.array(y_true)\n",
        "\n",
        "            valid_idx = y_true != -1\n",
        "            X_test = X_test[valid_idx]\n",
        "            y_true = y_true[valid_idx]\n",
        "\n",
        "            y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "            target_names = [self.reverse_map[i] for i in sorted(np.unique(y_true))]\n",
        "            print(\"\\n=== Test Results ===\")\n",
        "            print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))\n",
        "\n",
        "            return y_true, y_pred\n",
        "\n",
        "    return ASLProcessor()\n",
        "\n",
        "# STEP 4: Load and process data\n",
        "processor = get_processor()\n",
        "X_train, y_train = processor.load_train_data(data_train_dir)\n",
        "y_train = utils.to_categorical(y_train, len(processor.class_map))\n",
        "\n",
        "# STEP 5: Build and train best model (model_deep)\n",
        "model = models.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(63,)),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(len(processor.class_map), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=2)\n",
        "\n",
        "# STEP 6: Evaluate\n",
        "processor.evaluate_model(model, data_test_dir)\n",
        "\n",
        "# STEP 7: Convert and save to TensorFlow.js format\n",
        "output_dir = '/content/drive/MyDrive/SignLanguageDataset/models/tfjs_model'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "tfjs.converters.save_keras_model(model, output_dir)\n",
        "print(f\"\\n✅ Model converted and saved to {output_dir}\")\n",
        "\n",
        "# OPTIONAL STEP 8: Zip the model directory\n",
        "!zip -r /content/tfjs_model.zip /content/drive/MyDrive/SignLanguageDataset/models/tfjs_model"
      ]
    }
  ]
}